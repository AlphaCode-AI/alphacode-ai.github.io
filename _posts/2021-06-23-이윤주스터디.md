---
layout: post
published: true
title: "합성곱 신경망을 사용한 이미지 분류"
Date: 2021-06-23
tags: [study, 스터디]
---


# 합성곱 신경망을 사용한 이미지 분류

 - 합성곱, 필터, 패딩, 스트라이드, 풀링 등의 개념 -> 텐서플로 사용 시 직접 계산할 필요 없음
 - 복잡한 계산은 keras에 맡기고 사용자는 직관적으로 신경망 설계 가능




## 패션 MNIST 데이터 불러오기 

 - keras API를 사용해 패션 MNIST 데이터 불러오고 전처리 -> 데이터 스케일 0 ~ 255 사이에서 0 ~ 1 사이로 바꾸고 훈련세트와 검증세트로 나눔
 - 합성곱 신경망은 2차원 이미지를 그대로 사용하기 때문에 일렬로 펼치지 않는다
 - 입력 이미지는 항상 깊이 (채널) 차원이 있어야함
 - 흑백 이미지의 경우 채널차원이 없는 2차원 배열이지만 Conv2D 층을 사용하기 위해 이 채널 차원을 마지막에 추가해야함 
 - 넘파이 reshape() 함수를 이용하여 전체 배열 차원을 그대로 유지하면서 마지막에 차원 간단히 추가 가능



```python
from tensorflow import keras
from sklearn.model_selection import train_test_split
(train_input, train_target), (test_input, test_target) = keras.datasets.fashion_mnist.load_data()
train_scaled = train_input.reshape(-1, 28, 28, 1)/255.0
train_scaled, val_scaled, train_target, val_target = train_test_split(train_scaled, train_target, test_size=0.2, random_state=42)
```


![png](/assets/img/yunju/cnn_image/imageexample.png)


![png](/assets/img/yunju/cnn_image/pixelexample.png)



## 합성곱 신경망 만들기

 - 합성곱 신경망의 구조 : 합성곱 층으로 이미지에서 특징 감지 -> 밀집층으로 클래스에 따른 분류 확률 계산
 - 케라스의 Sequential 클래스를 사용해서 구조 정의 가능




### 1) 객체 생성 후 합성곱 층 추가

 - Sequential 클래스의 객체를 만들고 첫 번째 합성곱 층인 Conv2D 추가.
 - keras.layers 패키지 아래에 있는 클래스.


```python
model = keras.Sequential()
model.add(keras.layers.Conv2D(32, kernel_size=3, activation='relu', padding='same', input_shape=(28,28,1)))
```




### 2) 풀링 층 추가

 - keras.layers 패키지에서 MaxPooling2D(최대 풀링)와 AveragePooling2D(평균 풀링) 클래스 제공
 - (2,2) 최대 풀링 사용


```python
model.add(keras.layers.MaxPooling2D(2))
```




### 3) 두번째 합성곱 층 추가

 - 첫번째 합성곱층과 거의 동일하며 필터의 개수가 64개로 늘어남


```python
model.add(keras.layers.Conv2D(64, kernel_size=3, activation='relu', padding='same'))
```




### 4) 두번째 풀링 층 추가

 - 위의 두 합성곱 층은 세임 패딩을 사용 -> 입력의 가로 세로 크기를 줄이지 않음
 - 풀링 층에서 이 크기를 절반으로 줄임
 - 64개의 필터를 사용했으므로 최종적으로 만들어지는 특성 맵의 크기는 (7,7,64)


```python
model.add(keras.layers.MaxPooling2D(2))
```




### 5) 3차원 특성 맵 일렬로 펼치기

 - 마지막에 10개의 뉴런을 가진 (밀집)출력층에서 확률 계산하기 때문
 - 여기서는 특성 맵을 일렬로 펼쳐서 바로 출력층에 전달하지 않고 중간에 하나의 밀집 은닉층을 더 둠
 - Flatten -> Dense 은닉층 -> Dense 출력층
 - 은닉층과 출력층 사이에 dropout 층이 은닉층의 과대적합을 막아 성능을 좀 더 개선해줌


```python
model.add(keras.layers.Flatten())
model.add(keras.layers.Dense(100, activation='relu'))
model.add(keras.layers.Dropout(0.4))
model.add(keras.layers.Dense(10,activation='softmax'))
```




### 6) 모델 구조 출력

 - 첫번째 합성곱 층을 통과하면서 특성 맵의 깊이는 32가 되고 두번째 합성곱에서 특성 맵의 크기가 64로 늘어남
 - 특성맵의 가로세로 크기는 첫 번째 풀링 층에서 절반으로 줄어들고 두 번째 풀링 층에서 다시 절반으로 더 줄어듬
 - 따라서 최종 특성 맵의 크기는 (7,7,64) 


```python
model.summary()
```


![png](/assets/img/yunju/cnn_image/resultimage.png)




 - 모델 파라미터 개수 계산
    - 첫 번째 합성곱 층 -> 32개 필터, 크기 (3,3), 갚이 1, 필터마다 하나의 절편 -> 3 * 3 * 1 * 32 + 32 = 320개
    - 두 번째 합성곱 층 -> 64개 필터, 크기 (3,3), 깊이 32, 필터마다 하나의 절편 -> 3 * 3 * 32 * 64 + 64 = 18496개
    - 은닉층 -> (7,7,64) 특성 맵 1차원 배열로 펼치면 (3136,). 이를 100개의 뉴런과 완전히 연결해야함 -> 3136 * 100 + 100 = 313700개
    - 출력층 -> (100, ) 사이즈의 1차원 배열. 이를 10개의 뉴런과 완전히 연결해야함 -> 100 * 10 + 10 = 1010개



![png](/assets/img/yunju/cnn_image/result.png)



```python
keras.utils.plot_model(model)
```




![png](/assets/img/yunju/cnn_image/output_13_0.png)




```python
keras.utils.plot_model(model, show_shapes=True, to_file='cnn-architecture.png', dpi=300)
```




![png](/assets/img/yunju/cnn_image/output_14_0.png)




## 모델 컴파일과 훈련

 - 케라스의 장점 : 딥러닝 모델의 종류나 구성 방식에 상관없이 컴파일과 훈련 과정이 같다
 - Adam 옵티마이저를 사용하고 ModelCheckpoint 콜백과 EarlyStopping 콜백을 함께 사용해서 조기 종료 기법 구현
 - EarlyStopping 클래스에서 restore_best_weights 매개변수를 true로 지정 -> 현재 model 객체가 최적의 모델 파라미터로 복원되어 있음.


```python
model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics='accuracy')
checkpoint_cb = keras.callbacks.ModelCheckpoint('best-cnn-model.h5')
early_stopping_cb= keras.callbacks.EarlyStopping(patience=2, restore_best_weights=True)
history = model.fit(train_scaled, train_target, epochs=20, validation_data=(val_scaled, val_target),
                   callbacks=[checkpoint_cb, early_stopping_cb])
```


![png](/assets/img/yunju/cnn_image/epoch.jpeg)




## 성능 평가

 - 세트에 대한 성능
 - fit() 메서드의 출력 중 9번째 에포크의 출력과 동일


```python
import matplotlib.pyplot as plt
```


```python
plt.plot(history.history['loss'])
plt.plot(history.history['val_loss'])
plt.xlabel('epoch')
plt.ylabel('loss')
plt.legend(['train','val'])
plt.show()
```


![png](/assets/img/yunju/cnn_image/output_19_1.png)


```python
model.evaluate(val_scaled, val_target)
```


![png](/assets/img/yunju/cnn_image/val_evaluate.png)




 - 첫 번째 샘플 이미지 확인
 - matplotlib에서는 흑백 이미지에 깊이 차원 없음. (28,28,1) 크기를 (28,28)로 바꾸어 출력해야함


```python
plt.imshow(val_scaled[0].reshape(28,28),cmap='gray_r')
```


    <matplotlib.image.AxesImage at 0x1fb104bd8c8>




![png](/assets/img/yunju/cnn_image/output_21_1.png)



```python
preds = model.predict(val_scaled[:1])
print(preds)
```


![png](/assets/img/yunju/cnn_image/bag_proba.png)




```python
plt.bar(range(1,11), preds[0])
plt.xlabel('class')
plt.ylabel('prob.')
plt.show()
```


![png](/assets/img/yunju/cnn_image/output_23_0.png)


 - 9번째 값이 1이고 다른 값은 거의 0에 가까움




 - fashion MNIST dataset 에 정의된 레이블
 - 각 이미지는 하나의 레이블에 매핑되어 있음
 - 데이터셋에 클래스 이름이 들어있지 않기 때문에 이미지를 출력할 때 사용하기 위해 별도의 변수를 만들어 저장

 ![png](/assets/img/yunju/cnn_image/label.png)

```python
classes = ['T-shirt','Trouser','Pullover','Dress','Coat','Sandal','Shirt','Sneaker','Bag','Ankle boot']
```


```python
import numpy as np
print(classes[np.argmax(preds)])
```

    Bag




## 테스트세트 평가

 - 훈련세트와 검증세트에서 했던 것처럼 픽셀값의 범위를 0 ~ 1 사이로 바꾸고 이미지 크기 (28,28)에서 (28,28,1)로 바꿈
 - evaluate() 함수로 테스트 세트에 대한 성능 측정


```python
test_scaled = test_input.reshape(-1, 28, 28, 1)/255.0
```


```python
model.evaluate(test_scaled, test_target)
```


![png](/assets/img/yunju/cnn_image/test_proba.png)


