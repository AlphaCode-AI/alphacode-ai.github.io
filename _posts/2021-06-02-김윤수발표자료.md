---
layout: post
published: true
title: 김윤수발표자료
excerpt:
tags: study 스터디
author: yunsu
---
# Gradient Descent
[Statquest - Gradient Descent](https://www.youtube.com/watch?v=sDv4f4s2SB8&t).

# Stochastic Gradient Descent
[Statquest - Stochastic Gradient Descent](https://www.youtube.com/watch?v=vMh0zPT0tLI&t).

# SGD 예시
'''
# https://teddylee777.github.io/scikit-learn/gradient-descent

from sklearn.linear_model import LinearRegression
import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
from sklearn.preprocessing import PolynomialFeatures
'''

'''
def make_linear(w=0.5, b=0.8, size=50, noise=1.0):
    x = np.random.rand(size)
    y = w * x + b
    noise = np.random.uniform(-abs(noise), abs(noise), size=y.shape)
    yy = y + noise
    plt.figure(figsize=(10, 7))
    plt.plot(x, y, color='r', label=f'y = {w}*x + {b}')
    plt.scatter(x, yy, label='data')
    plt.legend(fontsize=20)
    plt.show()
    print(f'w: {w}, b: {b}')
    return x, yy
'''


'''
x, y = make_linear(w=0.3, b=0.5, size=100, noise=0.07)

plt.figure(figsize=(10, 7))
plt.scatter(x, y)
plt.show()
'''

'''
errors = []
# random 한 값으로 w, b를 초기화
w = np.random.uniform(low=-1.0, high=1.0)
b = np.random.uniform(low=-1.0, high=1.0)

for epoch in range(num_epoch):
    y_hat = x * w + b

    error = ((y_hat - y)**2).mean()
    if error < 0.0005:
        break
    
    w = w - learning_rate * ((y_hat - y) * x).mean()
    b = b - learning_rate * (y_hat - y).mean()
    
    errors.append(error)
    
    if epoch % 5 == 0:
        print("{0:2} w = {1:.5f}, b = {2:.5f} error = {3:.5f}".format(epoch, w, b, error))

print("----" * 15)
print("{0:2} w = {1:.1f}, b = {2:.1f} error = {3:.5f}".format(epoch, w, b, error))
'''