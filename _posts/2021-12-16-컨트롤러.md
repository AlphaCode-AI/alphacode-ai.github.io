---
Layout: post
Published: true
title: "controller"
date: 2021-12-16
excerpt: "controller"
tags: [Docker,Container volume, AI, ML, Artificial intelligence, machine learning, megazone, ai center]
author: gem
---

## Controller
- pod를 관리하는 역할, pod의 개수를 결정하고 보장해줌
- API, etcd,scheduler, cotroller 가 함께 협업하면서 pod의 개수를 보장 
    - 요청하여 보장해놓은 pod 중 하나에 문제가 생기게되면
    - controller가 API에게 pod 하나를 더 만들도록 요청 
    - scheduler를 통하여 pod를 배치하도록 하여 요청된 pod의 개수를 보장


## 컨트롤러의 종류 
![png](/assets/img/Gem/controller/컨트롤러의종류.png)

# 1. Replication Controller(RC)

-  요구하는 pod의 개수를 보장하며 파드 집합의 실행을 항상 안정적으로 유지하는 것을 목표
    - 요구하는 pod의 개수가 부족하면 template를 이용해서 pod 추가
    - 요구하는 pod 수 보다 많으면 최근에 생성된 pod를 삭제
- 기본 구성
    - selector : RC가 관리할 Pod를 가져오는 데 사용
    - replicas : RC에 의해서 관리되는 Pod의 수인데, 그 숫자만큼 Pod의 수를 유지
    - template : Pod를 새로 만들 때 어떤 Pod를 만들지에 대한 정보가 필요한데 (도커 이미지, 포트, 라벨 등) 이에 대한 정보를 정의한 템플릿


![png](/assets/img/Gem/controller/RC동작원리.png)


### 레플리케이션 컨트롤러 예제1

```
$ cat rc-nginx.yaml
apiVersion: v1
kind: ReplicationController
metadata:
  name: rc-nginx
spec:
  replicas: 3 # 배포 갯수
  selector:
    app: webui # key:value 이런 key, value를 가지는 pod를 replicas 수 만큼 운영해줘
  template: # 추가로 pod를 생성할 경우 pod template를 보고 생성 
    metadata:
      name: nginx-pod
      labels:
        app: webui # selector에 있는 key, value를 반드시 라벨로 포함하고 있어야 함
    spec:
      containers:
      - name: nginx-container
        image: nginx:1.14
 
```   


```
$ kubectl create -f rc-nginx.yaml
```

- 현재 동작중인 pod 수
```
$ watch kubectl get pods -o wide
```

-  rc의 정보를 출력(2가지 방법)
```
$ kubectl get replicationcontrollers
$ kubectl get rc
```

- rc의 정보를 자세하게 출력
```
$ kubectl describe rc rc-nginx
```

- 파드 삭제 시 replication controller가 하는 일은?
```
$ kubectl get pods
$ kubectl delete pod rc-nginx-XXXX
```



### 레플리케이션 컨트롤러 예제2 

- yaml 파일 수정하여 pod scale out/down

```
$ cat edit rc-nginx.yaml
apiVersion: v1
kind: ReplicationController
metadata:
  name: rc-nginx
spec:
  replicas: 3 
  selector:
    app: webui # key:value 이런 key, value를 가지는 pod를 replicas 수 만큼 운영해줘
  template: # 추가로 pod를 생성할 경우 pod template를 보고 생성 
    metadata:
      name: nginx-pod
      labels:
        app: webui # selector에 있는 key, value를 반드시 라벨로 포함하고 있어야 함
    spec:
      containers:
      - name: nginx-container
        image: nginx:1.14
 
```   

- command로 pod scale out/down

```
$ kubectl scale rc rc-nginx --relicas=3
```

 


### 버전 변경
- 서비스 동작 중에 새로 생성되는 pod의 버전 변경 가능(Rolling Update)
- 기존 pod에 영향은 없음

```
$ cat edit rc-nginx.yaml
apiVersion: v1
kind: ReplicationController
metadata:
  name: rc-nginx
spec:
  replicas: 3 
  selector:
    app: webui # key:value 이런 key, value를 가지는 pod를 replicas 수 만큼 운영해줘
  template: # 추가로 pod를 생성할 경우 pod template를 보고 생성 
    metadata:
      name: nginx-pod
      labels:
        app: webui # selector에 있는 key, value를 반드시 라벨로 포함하고 있어야 함
    spec:
      containers:
      - name: nginx-container
        image: nginx:1.15 # 새로 생성되는 
 
```   

- 동작중인 pod 확인

```
$ kubectl describe pod rc rc-nginx-XXX
```

- pod 삭제(rc 삭제하면 pod까지 다 삭제)

```
$ kubectl delete pod rc rc-nginx-XXX
```

- pod 삭제로 생성된 새로운 pod 확인

```
$ kubectl describe pod rc rc-nginx-YYY
```



# 2. ReplicaSet
- replication controller와 같은 역할을 하는 컨트롤러
- replication controller 보다 더 다양한 형태의 selector 지원


```
selector:
    matchLabels:
        component: redis
    matchExpressions: # 다양다양
    - {key: tier, operator: In, values: [cache]}
    - {key: environment, operator: Notln, values: [dev]}
```


-  matchExpressions 연산자
    - In : key와 values를 지정하여 key,value가 일치하는 pod만 연결
    - Notln : key는 일치하고 value는 일치하지 않는 pod에 연결
    - Exists : key에 맞는 label의 pod를 연결 
    - DoesNotExist : key와 다른 label의 pod를 연결 




```
$cat rs-nginx.yaml
apiVersion: apps/v1
kind: ReplicaSet
metadata:
  name: rs-nginx
spec:
  replicas: 3
  selector:
    matchLabels:
      app: webui 
  template: 
    metadata:
      name: nginx-pod
      labels:
        app: webui 
    spec:
      containers:
      - name: nginx-container
        image: nginx:1.14
```

```
$ kubectl create -f rs-nginx.yaml
```

- 동작중인 pod 수 확인

```
$ watch kubectl get pods -o wide
```

- rs의 정보를 출력(2가지 방법)

```
$ kubectl get replicasets
$ kubectl get rs
```


```
$ kubectl describe rs rs-nginx
```

- 파드 삭제시 rc가 하는 일은? 컨트롤러가 pod 수 계속 유지


```
$ kubectl get pods
$ kubectl delete pod rs-nginx-XXXX
```


- pod는 그대로 두고 컨트롤러만 삭제


```
$ kubectl delete rs rs-nginx --cacade=false # 연쇄 삭제 기능을 비활성화 하는 옵션
$ kubectl get rs
$ kubectl get pods
$ kubectl delete pod --all
```
 
 # 3. Deployment
  - ReplicaSet을 제어해주는 부모 역할, ReplicaSet을 컨트롤해서 pod 수 조절
  - 목적 : Rolling Update & Rolling Back
    - Rolling Update
        - 파드 인스턴스를 점진적으로 새로운 것으로 업데이트 하여 deployment update가 서비스 중단 없이 이루어질 수 있도록 함
    - Rolling Back : 이전 버전으로

### 예제


```
$cat deploy-nginx.yaml
apiVersion: apps/v1
kind: Deployment
metadata:
  name: deploy-nginx
spec:
  replicas: 3
  selector:
    matchLabels:
      app: webui 
  template: 
    metadata:
      name: nginx-pod
      labels:
        app: webui 
    spec:
      containers:
      - name: nginx-container
        image: nginx:1.14
```



```
$ kubectl create -f deploy-nginx.yaml
```

- 동작중인 pod 수 확인


```
$ watch kubectl get pods -o wide
```

- rs를 지워도 deployment가 rs를 다시 생성하여 유지할 수 있도록 함(deploy가 최상위 개념)


```
$ kubectl delete rs deploy-nginx-XXX
```


```
$ kubectl get deployments
$ kubectl get replicasets
$ kubectl get pods
```

```
$ kubectl delete deployment deploy-nginx
```


### Rolling Update & Rolling Back

- Rolling Update

```
$ kubectl set image deployment <deploy_name> <container_name> = <new_version image>
```

- Rolling Back


```
$ kubectl rollout history deployment <deploy_name>
$ kubectl rollout undo deploy <deploy_name>
```

### doploy 예제1

```
$cat deploy-nginx.yaml
apiVersion: apps/v1
kind: Deployment
metadata:
  name: app-deploy
spec:
  replicas: 3
  selector:
    matchLabels:
      app: webui 
  template: 
    metadata:
      name: nginx-pod
      labels:
        app: webui 
    spec:
      containers:
      - image: nginx:1.14
        name: web
        ports :
        - containerPort: 80
```

```
$ kubectl create -f deployment-exam.ymal --record
$ kubectl get deployment,rs,pod,svc

# Rolling Update
$ kubectl set image deploy app-deploy web=nginx:1.15 --record # record옵션: 업데이트 과정을 history로 기록
$ kubectl set image deploy app-deploy web=nginx:1.16 --record
$ kubectl set image deploy app-deploy web=nginx:1.17 --record

# controlling Rolling Update
$ kubectl rollout pause deploy app-deploy # 업데이트 일시정지
$ kubectl rollout resume deploy app-deploy # 업데이트 재시작
$ kubectl rollout status deploy app-deploy # 업데이트 상태 
$ kubectl rollout history deployment app-deploy # deploy 히스토리 확인
$ kubectl rollout undo deployment app-deploy # 이전 버전으로 롤백
$ kubectl rollout undo deployment app-deploy --to-revision=3 # revision=3으로 롤백
 
```

### doploy 예제2
- yaml 파일로 수정


```
$cat deployment-exam2.yaml
apiVersion: apps/v1
kind: Deployment
metadata:
  name: deploy-nginx
  annotations: 
    kubernetes.io/change-cause: version 1.14
spec:
  progressDeadlineSeconds:600
  revisionHistoryLimit: 10
  strategy:
    rollingUpdate:
        maxSurge: 25%
        maxUnavailable: 25%
    type: RollingUpdate

  replicas: 3
  selector:
    matchLabels:
      app: webui 
  template: 
    metadata:
      name: nginx-pod
      labels:
        app: webui 
    spec:
      containers:
      - image: nginx:1.14
        name: web
        ports :
        - containerPort: 80
```

```
$ kubectl apply -f deployment-exam2.yaml 
$ kubectl get deployment,rs,pod,svc

# 이미지 업데이트
$ vi deployment-exam2.yaml
->  annotations: 
    kubernetes.io/change-cause: version 1.15
    ...
    spec:
    containers:
    - image: nginx:1.15
    name: web

#apply
$ kubectl apply -f deployment-exam2.yaml 

# 히스토리 확인 & 이미지 롤백
$ kubectl rollout history deployment app-deploy 
$ kubectl rollout undo deployment app-deploy 

```

# 4. DaemonSet
- 전체 노드에서 pod가 노드당 한 개씩 실행되도록 보장
    - 노드에서 실행되는 pod가 문제가 생길 경우 삭제 된 후 노드 생성해주는 역할
- 로그 수입기, 모니터링 에이전트와 같은 프로그램 실행시 적용

```
$cat daemonset-nginx.yaml
apiVersion: apps/v1
kind: DaemonSet
metadata:
  name: daemonset-nginx
spec:
  replicas: 3
  selector:
    matchLabels:
      app: webui 
  template: 
    metadata:
      name: nginx-pod
      labels:
        app: webui 
    spec:
      containers:
      - image: nginx:1.14
        name: nginx-container
```

```
$ kubectl create -f daemonset-nginx.yaml

$ kubectl get daemonset
$ kubectl get pods

# daemonset으로 동작중인 pod 삭제하면?
$ kubectl delete daemonset-nginx-XXX # daemonset rolling update - 실행되고 있던 컨테이너 버전 수정 변경
$ kubectl edit ds daemonset-nginx

...

->       containers:
      - image: nginx:1.15 # rolling back
      
$ kubectl rollout undo daemonset daemonset-nginx # 삭제
$ kubectl delete daemonsets.apps daemonset-nginx

```

# 5. statefulset
- pod의 상태를 유지해주는 컨트롤러
    - pod 이름
        - 컨트롤러를 이용해서 pod 삭제 및 재생성할 경우 pod의 이름이 보장되지 않고 생성됨
        - statefulset 으로 실행할 경우, 순차적으로 번호가 붙어 생성됨
        - 생성 순서에 따른 번호가 붙어 pod 이름이 보장
    - pod 볼륨(스토리지)



```
$cat statefulset-exam.yaml
apiVersion: apps/v1
kind: StatefulSet
metadata:
  name: sf-nginx
spec:
  replicas: 3
  serviceName: sf-service
  podManagementPolicy: Parallel
  selector:
    matchLabels:
      app: webui 
  template: 
    metadata:
      name: nginx-pod
      labels:
        app: webui 
    spec:
      containers:
      - name: nginx-container
        image: nginx:1.14

```


```
$ kubectl create -f statefulset-exam.yaml 
$ kubectl get statefulsets,pod # 동작중인 두번째 pod 삭제 -> 1번이 완전히 삭제될때까지 기다린 다음 1번을 생성함

$ kubectl delete pod sf-nginx-1

# scale down / up
$ kubectl scale statefulset sf-nginx --replicas=2 # 2번 pod 삭제
$ kubectl scale statefulset sf-nginx --replicas=4 # 3번 pod 생성

# rolling update / rolling back
$ kubectl edit statefulsets.apps sf-nginx 
$ kubectl rollout undo statefulsets.apps sf-nginx 

```


# 6. JOB
- Kubernetessms pod를 running중인 상태로 유지
- Batch 처리하는 pod는 작업이 완료되면 종료됨
- Batch 처리에 적합한 컨트롤러로 pod의 성공적인 완료를 보장
    - 비정상 종료 시 다시 실행
    - 정상 종료시 완료



```
$cat job-exam.yaml
apiVersion: batch/v1
kind: Job
metadata:
  name: centos-job
spec:
  # completions: 5 # 실행해야 할 job의 수가 몇개인지 지정
  # parallelism: 2 # 병렬성. 동시 running되는 pod 수
  # activeDeadlineSecons: 15 # 지정 시간 내에 job을 완료, 지정 시간안에 끝나지 않으면 강제 완료
  template: 
    spec:
      containers:
      - name: centos-container
        image: centos:7
        command: ["bash"]
        args:
        - "-c"
        - "echo 'Hello World'; sleep 50; echo 'Bye'"
      restartPolicy: Never # 비정상 종료시 pod만 restart
      # restartPolicy: OnFailure  # 비정상 종료시 컨테이너를 restart
      # backoffLimit : 3 # restart limit 까지 restart 되고 그래도 안되면 작업자체를 삭제


```


- 50초 동안 실행
    - 50초 이내에 비정상 종료되면 -> 다시 pod 생성하여 재수행
    - 50초 후 정상 종료되면 끝(더이상의 실행 x)


```
$ kubectl create -f job-exam.yaml
$ kubectl get job,pods
$ kubectl get pods
$ kubectl delete jobs.apps centos-job

```


# 7. CronJob
-  CronJob안에 job의 컨트롤 기능 포함, job 컨트롤러로 실행할 application pod를 주기적으로 반복하여 실행
- Linux의 cronjob의 스케줄링 기능을 job controller에 추가한 API(사용자가 원하는 사간에 job 실행 예약 지원)
- 다음과 같은 반복해서 실행하는 job을 운영해야 할 때 사용
    - Data Backup
    - Send email
    - Cleaning tasks

- Cronjob Schedule: "0 3 1 * * "
    - Minutes (from 0 to 59)
    - Hours (from 0 to 23)
    - Day (from 1 to 31)
    - Month (from 1 to 12)
    - Day of the week (from 0 to 6)



![png](/assets/img/Gem/controller/cronjobschedule_1.png)
![png](/assets/img/Gem/controller/cronjobschedule_2.png)
![png](/assets/img/Gem/controller/cronjobschedule_3.png)
![png](/assets/img/Gem/controller/cronjobschedule_4.png)
![png](/assets/img/Gem/controller/cronjobschedule_5.png)  

  
```
$cat cronjob-exam.yaml
apiVersion: batch/v1beta1
kind: CronJob
metadata:
  name: cronjob-exam
spec:
  schedule: "* * * * *"
  startingDeadlineSeconds: 500  
  # successfulJobHistoryLimit: 3 # 성공한 job에 대해서 history 3개까지만 남기겠어
  concurrencyPolicy: Forbid  # 한번에 하나씩만 running
# concurrencyPolicy: ALLOW # 한번에 여러개의 job이 running 중이어도 됨
  jobTemplate: 
    spec:
      template:
        spec:
          containers:
      - name: hello
        image: busybox
        args:
        - /bin/sh
        - -c
        - "echo 'Hello World'; sleep 10; echo 'Bye'"
      restartPolicy: Never

```


```
$ kubectl create -f cronjob-exam.yaml
$ kubectl get cronjob
$ kubectl get pods
$ kubectl delete cronjob cronjob-exam
``` 


