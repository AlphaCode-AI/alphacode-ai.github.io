---
layout: post
title: 3-2.선형 함수
published: true
date:   2021-06-03
author: jinah

tags: [study, jinah]
---





### Prepreperation
- train set을 아래와 같이 세팅하고 훈련합니다

>
> Train Set
>
>
>```
>
>import numpy as np
>
perch_length = np.array(
   [8.4, 13.7, 15.0, 16.2, 17.4, 18.0, 18.7, 19.0, 19.6, 20.0,
    21.0, 21.0, 21.0, 21.3, 22.0, 22.0, 22.0, 22.0, 22.0, 22.5,
    22.5, 22.7, 23.0, 23.5, 24.0, 24.0, 24.6, 25.0, 25.6, 26.5,
    27.3, 27.5, 27.5, 27.5, 28.0, 28.7, 30.0, 32.8, 34.5, 35.0,
    36.5, 36.0, 37.0, 37.0, 39.0, 39.0, 39.0, 40.0, 40.0, 40.0,
    40.0, 42.0, 43.0, 43.0, 43.5, 44.0]
    )
>    
perch_weight = np.array(
   [5.9, 32.0, 40.0, 51.5, 70.0, 100.0, 78.0, 80.0, 85.0, 85.0,
    110.0, 115.0, 125.0, 130.0, 120.0, 120.0, 130.0, 135.0, 110.0,
    130.0, 150.0, 145.0, 150.0, 170.0, 225.0, 145.0, 188.0, 180.0,
    197.0, 218.0, 300.0, 260.0, 265.0, 250.0, 250.0, 300.0, 320.0,
    514.0, 556.0, 840.0, 685.0, 700.0, 700.0, 690.0, 900.0, 650.0,
    820.0, 850.0, 900.0, 1015.0, 820.0, 1100.0, 1000.0, 1100.0,
    1000.0, 1000.0]
    )
>
>```
>
>




>Train Set과 Test Set으로 나누기
>  
> ```
> from sklearn.model_selection import train_test_split
>
# 훈련 세트와 테스트 세트로 나누기
train_input, test_input, train_target, test_target = train_test_split(
   perch_length, perch_weight, random_state=42)
>
# 훈련 세트와 테스트 세트를 2차원 배열로 변경
train_input = train_input.reshape(-1, 1)
test_input = test_input.reshape(-1, 1)
> ```




>Train
>
>```
>from sklearn.neighbors import KNeighborsRegressor
>
knr = KNeighborsRegressor(n_neighbors=3)
>
# k-최근접 이웃 회귀 모델을 훈련합니다
knr.fit(train_input, train_target)
>```
>
>
>score
>
> ``` 
> print(knr.score(test_input,test_target))
> 
> ```
> output : 0.992809406101064


## k-NN의 한계
- k-NN 모델을 이용하여 길이가 **50cm**인 농어의 무게 예측

>prediction
>
>```
>print(knr.predict([[50]]))
>```
> output : 1033.33333333



- Train Set과 예측값 시각화

>```
># 50cm 농어의 이웃을 구합니다
distances, indexes = knr.kneighbors([[50]])
>
# 훈련 세트의 산점도를 그립니다
plt.scatter(train_input, train_target)
# 훈련 세트 중에서 이웃 샘플만 다시 그립니다
plt.scatter(train_input[indexes], train_target[indexes], marker='D')
# 50cm 농어 데이터
plt.scatter(50, 1033, marker='^')
plt.xlabel('length')
plt.ylabel('weight')
plt.show()
>```
> output : 
> 
> <img src= "assets/img/img_0302/0302_1.png" width="300",height="200">



- 위와 같은 방법으로 k-NN 모델을 이용하여 길이가 **100cm**인 농어의 무게 예측
  
> output :
> 
> ![](/assets/img/img_0302/0302_2.png)
>


### k-NN의 한계

- k-NN(k-최근접 알고리즘) 은 input 값과 가장 최근접하는 이웃 n개의 평균 함으로써 예측하는 모델임(n = n_neighbor)
- **rain set의 범위를 벗어난 예측을 하지 못함**




## Linear Regression
- 위와 같은 한계점을 극복할 수 있는 알고리즘으로 선형 함수를 이용하여(직선) 예측을 수행 
- 간단하며 성능이 뛰어남

<img src= "https://github.com/MZCloudnoa/mzcloudnoa.github.io/blob/master/assets/img/img_0302/0302_3.png" width="300",height="200">
<img src= "https://github.com/MZCloudnoa/mzcloudnoa.github.io/blob/master/assets/img/img_0302/0302_4.png" width="300",height="200">

> Train
> 
> ```
> from sklearn.linear_model import LinearRegression
> 
> lr = LinearRegression()
> 
> # 선형 회귀 모델 훈련
> lr.fit(train_input, train_target)
> 
> ```
> output : LinearRegression()
 
=



> prediction
> 
>```
># 50cm 농어에 대한 예측
print(lr.predict([[50]]))
>```
>output : [1241.83860323]


- 직선(y = ax + b)을 그리기 위해서는 기울기와 절편, 즉 a와 b값이 있어야함
-  LinearRegression 클래스가 찾은 a,b값은 lr 객체의 coef_와 intercept_에 저장되어 있음

>
>LinearRegression 
>
>```
>print(lr.coef_, lr.intercept_)
>```
>output.: [39.01714496] -709.0186449535477


- 찾은 a,b값을 이용하여 선형함수를 그린다

>
> ```# 훈련 세트의 산점도를 그립니다
plt.scatter(train_input, train_target)
>
# 15에서 50까지 1차 방정식 그래프를 그립니다
plt.plot([15, 50], [15*lr.coef_+lr.intercept_, 50*lr.coef_+lr.intercept_])
>
# 50cm 농어 데이터
plt.scatter(50, 1241.8, marker='^')
plt.xlabel('length')
plt.ylabel('weight')
plt.show()
```
>output : 
>
><img src= "https://github.com/MZCloudnoa/mzcloudnoa.github.io/blob/master/assets/img/img_0302/0302_5.png" width="300",height="200">


- lr score 확인

>```
print(lr.score(train_input, train_target))
print(lr.score(test_input , test_target))
```
>output :
> 
>0.9398463339976041   
>0.8247503123313559



### Linear Regression 의 한계
-
- 아래 그림과 같이  lr을 사용하여 길이가 **5cm**인 농어를 예측했을 경우 무게가 음수값이 나옴
- 이는 현실에서는 나올 수 없는 경우임

<img src= "https://github.com/MZCloudnoa/mzcloudnoa.github.io/blob/master/assets/img/img_0302/0302_6.png"  width="300",height="200">

## Polynomial Regression
- 이러한 한계점을 극복하고 곡선으로 선형을 그려, 보다 최적화된 알고리즘을 찾을 수 있음
- 이차함수를 이용 (y = ax^2 + bx + c)


- train set 생성
> 넘파이를 이용하여 x의 제곱값과 x값으로 train set과 test set 생성
>
>```
>train_poly = np.column_stack((train_input ** 2, train_input))
test_poly = np.column_stack((test_input ** 2, test_input))
>
>print(train_poly.shape, test_poly.shape)
```
>output : (42, 2) (14, 2)

- train_poly만 찍어보면 아래와 같이 array가 생성됨
>
>```
>train_poly
>```
>
>output: 
>
>array([[ 384.16,   19.6 ],
       [ 484.  ,   22.  ],
       [ 349.69,   18.7 ],
       [ 302.76,   17.4 ],
       [1296.  ,   36.  ],
       [ 625.  ,   25.  ],
       [1600.  ,   40.  ],
       [1521.  ,   39.  ],
       [1849.  ,   43.  ],
       [ 484.  ,   22.  ],
       [ 400.  ,   20.  ],
       [ 484.  ,   22.  ],
       [ 576.  ,   24.  ],
       [ 756.25,   27.5 ],
       [1849.  ,   43.  ],
       [1600.  ,   40.  ],
       [ 576.  ,   24.  ] ...

- 길이가 **50cm**인 농어의 무게 예측
>prediction
>
>```
>lr = LinearRegression()
lr.fit(train_poly, train_target)
>
print(lr.predict([[50**2, 50]]))
>```
>output : [1573.98423528]




- y =  ax^2 + bx + c 와 같은 곡선함수를 만들기 위하여, LinearRegression 클래스 이용해서 a,b,c 값을 찾을 수 있음
>```
>print(lr.coef_, lr.intercept_)
>```
>output : [  1.01433211 -21.55792498] 116.0502107827827



- 찾은 a,b,c 값을 이용하여 다항함수를 그린다
>```
># 구간별 직선을 그리기 위해 15에서 49까지 정수 배열을 만듭니다
point = np.arange(15, 50)
>
# 훈련 세트의 산점도를 그립니다
plt.scatter(train_input, train_target)
>
# 15에서 49까지 2차 방정식 그래프를 그립니다
plt.plot(point, 1.01*point**2 - 21.6*point + 116.05)
>
# 50cm 농어 데이터
plt.scatter([50], [1574], marker='^')
plt.xlabel('length')
plt.ylabel('weight')
plt.show()
>```
>output :
> 
><img src= "https://github.com/MZCloudnoa/mzcloudnoa.github.io/blob/master/assets/img/img_0302/0302_7.png" width="300",height="200">
>
>
>

