---
layout: post
title: 3-2.선형 함수
published: true
date:   2021-06-03
author: jinah

tags: [study, jinah]
---



### 파라미터(Parameter)
-
>- 매개변수  
>- 모델의 구성 요소이자 데이터로부터 학습 되는 것.  
>- 모델 내부에서 결정되는 변수



### 하이퍼 파라미터(Hyper Parameter)
-
>- 학습 시작 전 미리 값을 결정하는 것
>-  사용자 지정 파라미터
>- 하이퍼 파라미터 튜닝을 자동으로 수행하는 기술을 Auto ML
>- 라이브러리가 제공하는 기본값을 그대로 사용해 모델 train > 교차검증 수행

### 교차 검증(Cross Validation)
> -  고정된 train set과 test set으로 평가를 하고, 반복적으로 모델을 튜닝하다보면 test set에만 과적합되는 결과 발생
> - 이러한 문제점을 교차검증을 통해 해결
> 
> 1. k-겹 교차 검증(k-fold cross validation)
-
-  데이터를 k개의 데이터 폴드로 분할
-  각 Iteration마다 test set을 다르게 할당하여 총 k개의 데이터 폴드 세트를 구성

>
<img src="https://mblogthumb-phinf.pstatic.net/MjAxOTA3MjVfMTYz/MDAxNTY0MDY1ODk4NTM0.HiTh5fw3_Fulbq6dv1iLrxS7EmEM4htsWC-5fh-TiGAg.5rbp2nHtWYOZvzoN-Kl4mCKF4nZ4rd5bmO_IDh-sieAg.PNG.ckdgus1433/image.png?type=w800">

>2.  리브-p-아웃 교차 검증(Leave-p-out cross validation)
-
>- 전체 데이터(서로 다른 데이터 샘플들) 중에서 p개의 샘플을 선택하여 그것을 모델 검증에 사용하는 방법

<img src="https://mblogthumb-phinf.pstatic.net/MjAxOTA3MjZfNCAg/MDAxNTY0MDY4NzA4MTEy.WMv-qZ490weZMjteert-trU-zIXBeX6wUs19A0Fo5RAg.KqxSpltjlbeYUTjj1d_V-HdPjYlzms_pKUmsJ1PipL0g.PNG.ckdgus1433/image.png?type=w800">

>3.  리브-p-아웃 교차 검증(Leave-p-out cross validation)
-
>- 리브-p-아웃 교차 검증에서 p=1일 때의 경우
>- 리브-p-아웃 교차 검증보다 계산 시간 부담 적음

<img src="https://mblogthumb-phinf.pstatic.net/MjAxOTA3MjZfNCAg/MDAxNTY0MDY4NzA4MTEy.WMv-qZ490weZMjteert-trU-zIXBeX6wUs19A0Fo5RAg.KqxSpltjlbeYUTjj1d_V-HdPjYlzms_pKUmsJ1PipL0g.PNG.ckdgus1433/image.png?type=w800">

>4.  계층별 k-겹 교차 검증(Stratified k-fold cross validation)
-
>- 주로 Classification 문제에서 사용되며, label의 분포가 각 클래스별로 불균형을 이룰 때 유용하게 사용
>- 리브-p-아웃 교차 검증보다 계산 시간 부담 적음

<img src="https://mblogthumb-phinf.pstatic.net/MjAxOTA3MjlfMiAg/MDAxNTY0NDA5MTY4MTkw.IlCY5_N8e3Qw1lU5DDufL0G1DYzIoWRgBDLlr4BY9JAg.qlE19XgVRk2CcFYTYZ7zHcuKtKjh8eQ-a4WYPhpE7V4g.PNG.ckdgus1433/image.png?type=w800">

## 하이퍼 파라미터 튜닝 방법

####1. Grid Search
> - 모델 하이퍼 파라미터에 넣을 수 있는 값들을 순차적으로 입력한뒤에 가장 높은 성능을 보이는 하이퍼 파라미터들을 찾는 탐색 방법
> 
>
 ```
params = {'min_impurity_decrease': np.arange(0.0001, 0.001, 0.0001),
          'max_depth': range(5, 20, 1),
          'min_samples_split': range(2, 100, 10)
          }
 params 
 ```
 
> output :
>
> {'min_impurity_decrease': array([0.0001, 0.0002, 0.0003, 0.0004, 0.0005, 0.0006, 0.0007, 0.0008, 0.0009]),
> 'max_depth': range(5, 20),  
> 'min_samples_split': range(2, 100, 10)}
> 
> 
> - 단점 :  모든 경우의 수를 다 넣기 때문에 숫자를 추가할 수록 시간이 아주 오래 걸린다

####2. Random Search
> - 하이퍼 파라미터 값을 랜덤하게 넣어보고 그중 우수한 값을 보인 하이퍼 파라미터를 활용해 모델을 생성
> - 불필요한 탐색 횟수를 줄인다
 ```
params = {'min_impurity_decrease': uniform(0.0001, 0.001),
          'max_depth': randint(20, 50),
          'min_samples_split': randint(2, 25),
          'min_samples_leaf': randint(1, 25),
          }         
params  
 ```
 
> output :
>
> {'min_impurity_decrease': <scipy.stats._distn_infrastructure.rv_frozen at 0x7fed449f9fd0>,
 'max_depth': <scipy.stats._distn_infrastructure.rv_frozen at 0x7fed44d52be0>,
 'min_samples_split': <scipy.stats._distn_infrastructure.rv_frozen at 0x7fed449f9130>,
 'min_samples_leaf': <scipy.stats._distn_infrastructure.rv_frozen at 0x7fed44befd90>}

<img src="https://img1.daumcdn.net/thumb/R1280x0/?scode=mtistory2&fname=https%3A%2F%2Fblog.kakaocdn.net%2Fdn%2FbbiSBu%2FbtqF3T0FGSi%2FvnJ5vH9oANNJL2SFdZTrA0%2Fimg.png">








https://colab.research.google.com/github/rickiepark/hg-mldl/blob/master/5-2.ipynb#scrollTo=dYI3HwMQbtnr